{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gslmFev7hWhu"
   },
   "source": [
    "<h1>Train data from Kaggle Twitter sentiment (Sentiment140 dataset with 1.6 million tweets)</h1>\n",
    "https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1W-cSRv_hnwU",
    "outputId": "42855fa5-a5f9-40f8-b000-1e1db81c6079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "\n",
    "\n",
    "pip install contractions\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#for data cleansing\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import contractions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4fRhYJHjmbE"
   },
   "source": [
    "# Clean Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7TuItbOgtuQ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/training.1600000.processed.noemoticonf.csv',encoding ='latin',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvXDxHnchWiH",
    "outputId": "949cc438-e36c-4836-c5ea-5f7dc0ce8826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xea4gmrphWiQ",
    "outputId": "75a84462-4927-44f7-9e58-acacf8f19380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     0\n",
       "tweet_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking  if any null value\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBOiZsyIhWiU"
   },
   "outputs": [],
   "source": [
    "# 0 is negative, 1 is positive >> replace 4 with 1\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x==4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gopkS6SYhWiX",
    "outputId": "ccf9f5a5-ee82-4aa1-f45c-4db04facd155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the sample is balanace or not \n",
    "#dataset are with target 0 on the first 80000 rows and target 1 on the last 80000 rows\n",
    "\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSvtUVYkhWif"
   },
   "outputs": [],
   "source": [
    "#shuffle the dataframe\n",
    "newdf = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gt9GPz0NhWim"
   },
   "outputs": [],
   "source": [
    "# Data clensing function\n",
    "\n",
    "def cleantext(text):\n",
    "\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'@[A-za-z0-9]+','',text) # remove @mentions\n",
    "    text = re.sub(r'RT[\\s]+','',text) #remove retweet\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text) #remove hyperlink\n",
    "    text = re.sub(r'#','',text) #remove #\n",
    "\n",
    "    text = text.replace('\\n',' ')\n",
    "\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    text = stemmer.stem(text)\n",
    "    text = re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=\\*\\\"\\'\\“\\(\\)\\_]\", \"\",text) # remove puntucation\n",
    "    text = re.sub(\"[0123456789]\", \"\", text) # remove number\n",
    "\n",
    "    text = text.replace('  ',' ')\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Apply clean text function\n",
    "\n",
    "newdf['tweet_text'] = newdf['tweet_text'].apply(cleantext)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pET2A8phdw0"
   },
   "source": [
    "# Start building the model with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1hzu_F7hWiw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTcT1U1LhWiz",
    "outputId": "b6b9e0d7-905e-4d83-b0ec-d9ba42f482f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120000\n",
      "480000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply Train test split\n",
    "\n",
    "X = newdf['tweet_text'].apply(str)\n",
    "y = newdf['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tyCDZE_hWi3"
   },
   "outputs": [],
   "source": [
    "#Tokenize and fit with training data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4OLilpahWi9"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train),maxlen = 200)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test),maxlen = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E1Vc2AChWjA"
   },
   "source": [
    "<h2>Load pre-trained word embeddings -  GloVe embeddings </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdCwlOZUhWjB",
    "outputId": "0034ac17-03d5-4c7c-8db0-cc60d6f684fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-16 16:54:26--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2020-11-16 16:54:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2020-11-16 16:54:28--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  1.21MB/s    in 11m 5s  \n",
      "\n",
      "2020-11-16 17:05:34 (1.24 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZ79tfsShWjF"
   },
   "outputs": [],
   "source": [
    "path_to_glove_file = \"/content/drive/My Drive/Colab Notebooks/glove.6B.200d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPdkplLKhWjN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    vocab_len,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdNWBUR0hWjR"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "638mwN_8hWjU",
    "outputId": "5a1a8019-632f-4840-b26b-c106fb34ee56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 200, 200)          64411600  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 196, 128)          128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 64,737,233\n",
      "Trainable params: 325,633\n",
      "Non-trainable params: 64,411,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = layers.Input(shape=(200,), dtype='int32')\n",
    "embedding_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedding_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obpzfpWihWjX",
    "outputId": "35a39423-717e-42ff-f5c6-4a10395240fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8750/8750 [==============================] - 1256s 143ms/step - loss: 0.4957 - accuracy: 0.7583 - val_loss: 0.4716 - val_accuracy: 0.7734\n",
      "Epoch 2/20\n",
      "8750/8750 [==============================] - 1245s 142ms/step - loss: 0.4634 - accuracy: 0.7794 - val_loss: 0.4630 - val_accuracy: 0.7786\n",
      "Epoch 3/20\n",
      "8750/8750 [==============================] - 1246s 142ms/step - loss: 0.4494 - accuracy: 0.7878 - val_loss: 0.4625 - val_accuracy: 0.7797\n",
      "Epoch 4/20\n",
      "8750/8750 [==============================] - 1250s 143ms/step - loss: 0.4390 - accuracy: 0.7945 - val_loss: 0.4653 - val_accuracy: 0.7797\n",
      "Epoch 5/20\n",
      "8750/8750 [==============================] - 1264s 144ms/step - loss: 0.4304 - accuracy: 0.7991 - val_loss: 0.4640 - val_accuracy: 0.7800\n",
      "Epoch 6/20\n",
      "8750/8750 [==============================] - 1246s 142ms/step - loss: 0.4230 - accuracy: 0.8039 - val_loss: 0.4602 - val_accuracy: 0.7810\n",
      "Epoch 7/20\n",
      "8750/8750 [==============================] - 1248s 143ms/step - loss: 0.4165 - accuracy: 0.8078 - val_loss: 0.4683 - val_accuracy: 0.7800\n",
      "Epoch 8/20\n",
      "8750/8750 [==============================] - 1274s 146ms/step - loss: 0.4101 - accuracy: 0.8111 - val_loss: 0.4783 - val_accuracy: 0.7785\n",
      "Epoch 9/20\n",
      "8750/8750 [==============================] - 1274s 146ms/step - loss: 0.4052 - accuracy: 0.8140 - val_loss: 0.4776 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9917dbd518>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, \n",
    "                                                 monitor = 'val_loss'),]\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=20, \n",
    "          validation_data=(X_test,y_test),callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZrF3NM513IY",
    "outputId": "86c2b0de-2851-4c09-8fcf-84c8e4a57dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/model/twitter_sentiment/assets\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save(\"/content/drive/My Drive/Colab Notebooks/model/twitter_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rIqpHaqiRFn"
   },
   "outputs": [],
   "source": [
    "#pickle and save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "twitter_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
